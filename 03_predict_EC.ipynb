{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1e5977",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Define parameters](#parameters)\n",
    "* [Class definitions](#class)\n",
    "* [Function definitions](#function)\n",
    "* [Run](#run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbd67c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import Tuple,  Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import typer\n",
    "from typing import List, Optional\n",
    "\n",
    "from torch import FloatTensor, LongTensor\n",
    "from torch import flatten, device, cuda, nn, from_numpy\n",
    "from torch import load as load_module\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional, Module\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from drfp import DrfpEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca919ea6",
   "metadata": {},
   "source": [
    "## Define parameters <a class=\"anchor\" id=\"parameters\"></a>\n",
    "\n",
    "In step 2 we have seen that the <code>ec123_drfp_mlp</code> model has the best accuracy. We will therefore use this model here to make the EC predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7919a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype='ec123_drfp_mlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1df5b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('experiments/predictions').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835cea1",
   "metadata": {},
   "source": [
    "## Class definitions <a class=\"anchor\" id=\"class\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "009a2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceReactionDataset(Dataset):\n",
    "    def __init__(self, rxns: List, label: str = \"label\"):\n",
    "        self.rxns = rxns\n",
    "        self.size = len(rxns)\n",
    "        self.label = label\n",
    "        \n",
    "        fps, _, _ = DrfpEncoder.encode(\n",
    "            rxns,\n",
    "            mapping=True,\n",
    "            atom_index_mapping=True,\n",
    "            root_central_atom=False,\n",
    "            radius=2,\n",
    "            include_hydrogens=True,\n",
    "            n_folded_length=10240,\n",
    "        )\n",
    "\n",
    "        self.X = FloatTensor(\n",
    "            np.array([x.astype(np.float32) for x in fps], dtype=np.float32)\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23e15750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.fc1(x)\n",
    "        tanh = self.tanh(hidden)\n",
    "        output = self.fc2(tanh)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "498d7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReactionDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, label: str = \"label\"):\n",
    "        self.size = len(df)\n",
    "        self.label = label\n",
    "        self.X = FloatTensor(\n",
    "            np.array([x.astype(np.float32) for x in df.fps], dtype=np.float32)\n",
    "        )\n",
    "        self.y = LongTensor(df[self.label].to_numpy(dtype=np.int32))\n",
    "        self.fps = df[\"fps\"]\n",
    "        self.rxn_smiles = df[\"rxn_smiles\"]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (\n",
    "            self.X[i],\n",
    "            self.y[i],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bb7581",
   "metadata": {},
   "source": [
    "## Function definitions <a class=\"anchor\" id=\"function\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2361e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if cuda.is_available():\n",
    "        return device(\"cuda:0\")\n",
    "    return device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6474585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(\n",
    "    source: str = \"rheadb\", names = [], split: str = \"0\", fplength: int = 10240\n",
    ") -> Dict[str, Tuple[MLPClassifier, LabelEncoder, Dataset]]:\n",
    "\n",
    "    models = {}\n",
    "\n",
    "    for name in names:\n",
    "        model_path = f\"models/{source}-{name}.pt\"\n",
    "\n",
    "        classifier = None\n",
    "        label_encoder = None\n",
    "\n",
    "        with open(f\"models/{source}-{name}-le.pkl\", \"rb\") as f:\n",
    "            label_encoder: LabelEncoder = pickle.load(f)\n",
    "\n",
    "        classifier = MLPClassifier(fplength, 1664, len(label_encoder.classes_))\n",
    "        classifier.load_state_dict(load_module(model_path))\n",
    "        classifier.eval()\n",
    "\n",
    "        models[name] = (classifier, label_encoder)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3952d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_internal(\n",
    "    model: Module,\n",
    "    device: device,\n",
    "    data_set: Dataset,\n",
    "    label_encoder: LabelEncoder,\n",
    "    topk: int = 10,\n",
    ") -> Tuple[str, Dict[str, float], List[int]]:\n",
    "    data_sample = next(iter(DataLoader(data_set)))\n",
    "    data_sample = data_sample.to(device)\n",
    "    pred_raw = model(data_sample)\n",
    "    probs = flatten(functional.softmax(pred_raw, dim=1)).cpu().detach().numpy()\n",
    "    pred = pred_raw.max(1, keepdim=True)[1]\n",
    "    y_pred = flatten(pred).tolist()\n",
    "\n",
    "    topk_indices = (-probs).argsort()[:topk]\n",
    "    probabilities = {\n",
    "        label_encoder.inverse_transform([i])[0]: prob for i, prob in enumerate(probs)\n",
    "    }\n",
    "\n",
    "    return label_encoder.inverse_transform(y_pred)[0], probabilities, topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "829e46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(\n",
    "    rxn, model, label_encoder, device, probs, topk, dataset\n",
    "):\n",
    "    \n",
    "    pred, probabilities, topk_indices = predict_internal(\n",
    "        model, device, dataset, label_encoder, topk\n",
    "    )\n",
    "\n",
    "    result = [pred]\n",
    "\n",
    "    if probs:\n",
    "        top_k_classes = [label_encoder.inverse_transform([i])[0] for i in topk_indices]\n",
    "        result.append({c: probabilities[c] for c in top_k_classes})\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab43b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model_id: str,\n",
    "    rxn_smiles: str,\n",
    "    topk: Optional[int] = 5,\n",
    "    explain: Optional[bool] = False,\n",
    "    probs: Optional[bool] = False,\n",
    "):\n",
    "    dataset = InferenceReactionDataset([rxn_smiles])\n",
    "    \n",
    "    vals = model_id.split(\".\")\n",
    "    models = load_models(vals[0], [vals[1]], '0', len(dataset[0]))\n",
    "\n",
    "    device = get_device()\n",
    "    model, label_encoder = models[vals[1]]\n",
    "    model = model.to(device)\n",
    "\n",
    "    result = predict_one(\n",
    "        rxn_smiles,\n",
    "        model,\n",
    "        label_encoder,\n",
    "        device,\n",
    "        probs,\n",
    "        topk,\n",
    "        dataset\n",
    "    )\n",
    "\n",
    "    return result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b31b9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_EC_with_probs(\n",
    "    model: str = typer.Argument(\n",
    "        ...,\n",
    "        help=\"The name of the model. Options are rheadb.ec1, rheadb.ec12, rheadb.ec123, ecreact.ec1, ecreact.ec12, and ecreact.ec123.\",\n",
    "    ),\n",
    "    rxn_smiles: str = typer.Argument(\n",
    "        ..., help=\"The reaction smiles in the form a.b>>c.d.\"\n",
    "    ),\n",
    "    topk: Optional[int] = 5,\n",
    "    probs: Optional[bool] = True,\n",
    "):\n",
    "    val = predict(model, rxn_smiles, topk, False, probs)\n",
    "    val = dict(filter(lambda elem: elem[1]>0.01, val.items()))\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5800ee71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3.5.1': 0.99916303}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for one smiles:\n",
    "predict_EC_with_probs(f'rheadb.{modeltype}', \"CCCCC(N)=O.[H]O[H]>>CCCCC(=O)[O-].[H][N+]([H])([H])[H]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7d663ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictECs(row):\n",
    "    try:\n",
    "        res = predict_EC_with_probs(f'rheadb.{modeltype}', row['rxn_smiles'])\n",
    "        return ' | '.join([f\"{key}:{value}\" for key, value in res.items()])\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        return 'No prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2e72361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(infile: str, outfile: str):\n",
    "    df = pd.read_csv(infile)\n",
    "\n",
    "    # Replace ecreact style reactions with standard reaction SMILES.\n",
    "    df[\"rxn_smiles\"] = df[\"rxn_smiles\"].str.replace(r\"\\|.*>\", \">>\", regex=True)\n",
    "\n",
    "    ddata = dd.from_pandas(df, npartitions=1000)\n",
    "    ProgressBar().register()\n",
    "    res = ddata.map_partitions(\n",
    "        lambda df: df.assign(EC_prediction=df.apply(predictECs, axis=1))).compute()\n",
    "    \n",
    "    res.to_csv(outfile, index=False, sep='\\t')\n",
    "    print('=> Created file', outfile)\n",
    "    print('=> Finished')\n",
    "    \n",
    "# Alternative main function with pandas instead of dask - slower!\n",
    "\n",
    "# def main(infile: str, outfile: str):\n",
    "#     df = pd.read_csv(infile)\n",
    "\n",
    "#     # Replace ecreact style reactions with standard reaction SMILES.\n",
    "#     df[\"rxn_smiles\"] = df[\"rxn_smiles\"].str.replace(r\"\\|.*>\", \">>\", regex=True)\n",
    "\n",
    "#     df_nan = df[~df.ec.notna()]\n",
    "\n",
    "#     tqdm.pandas()\n",
    "\n",
    "#     df_nan['EC predictions | probabilities'] = df_nan.progress_apply(predictECs, axis=1)\n",
    "#     df_nan.to_csv(outfile, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d445b",
   "metadata": {},
   "source": [
    "## Run <a class=\"anchor\" id=\"run\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e174f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[###                                     ] | 9% Completed |  8min 50.2s\n",
      "[###                                     ] | 9% Completed |  8min 50.4s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/rheadb.csv.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperiments/predictions/rheadb_predicted_ECs_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodeltype\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.tsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 9\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(infile, outfile)\u001b[0m\n\u001b[1;32m      7\u001b[0m ddata \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mfrom_pandas(df, npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      8\u001b[0m ProgressBar()\u001b[38;5;241m.\u001b[39mregister()\n\u001b[0;32m----> 9\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mddata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictECs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m res\u001b[38;5;241m.\u001b[39mto_csv(outfile, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=> Created file\u001b[39m\u001b[38;5;124m'\u001b[39m, outfile)\n",
      "File \u001b[0;32m/scratch/anaconda3/envs/rheaec/lib/python3.8/site-packages/dask/base.py:290\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/scratch/anaconda3/envs/rheaec/lib/python3.8/site-packages/dask/base.py:573\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    571\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 573\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/scratch/anaconda3/envs/rheaec/lib/python3.8/site-packages/dask/threaded.py:81\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     79\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 81\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m/scratch/anaconda3/envs/rheaec/lib/python3.8/site-packages/dask/local.py:495\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaiting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mready\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    494\u001b[0m     fire_tasks(chunksize)\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, res_info, failed \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqueue_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult():\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m    497\u001b[0m             exc, tb \u001b[38;5;241m=\u001b[39m loads(res_info)\n",
      "File \u001b[0;32m/scratch/anaconda3/envs/rheaec/lib/python3.8/site-packages/dask/local.py:133\u001b[0m, in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqueue_get\u001b[39m(q):\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/anaconda3/envs/rheaec/lib/python3.8/queue.py:170\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/anaconda3/envs/rheaec/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main('data/rheadb.csv.gz', f'experiments/predictions/rheadb_predicted_ECs_{modeltype}.tsv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheaec",
   "language": "python",
   "name": "rheaec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
